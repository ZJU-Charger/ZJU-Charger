# æ‰«æå°¼æ™®é¡¿è®¾å¤‡ä¿¡æ¯
import requests
import json
import argparse
import csv
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import List, Any, Generator, Tuple, Dict
from tqdm import tqdm
from collections import defaultdict


# --- æ ¸å¿ƒæŠ“å–å‡½æ•°ï¼ˆè¿”å›æ‰€æœ‰è¯¦ç»†æ•°æ®ï¼‰ ---
def get_device_info(address: str) -> Tuple[str, str, int, int, int] | None:
    """
    é€šè¿‡ POST è¯·æ±‚è·å–æŒ‡å®šè®¾å¤‡åœ°å€ (address) çš„è¯¦ç»†ä¿¡æ¯ã€‚
    æˆåŠŸè·å–åˆ°æœ‰æ•ˆæè¿°åˆ™è¿”å› (devid, devdescript, å¯ç”¨, å·²ç”¨, æ€»æ•°) å…ƒç»„ï¼Œå¦åˆ™è¿”å› Noneã€‚
    """
    try:
        response = requests.post(
            "http://www.szlzxn.cn/wxn/getDeviceInfo",
            data={"areaId": 6, "devaddress": address},
            timeout=5,
        )
        response.raise_for_status()

        data = response.json()
        obj = data.get("obj")

        # éªŒè¯æ˜¯å¦ä¸ºæœ‰æ•ˆè®¾å¤‡ï¼šå­˜åœ¨ obj ä¸” devdescript ä¸ä¸ºç©º
        if obj and obj.get("devdescript"):
            dev_description = obj.get("devdescript", "æœªçŸ¥è®¾å¤‡").strip()
            # å¦‚æœæè¿°æ˜¯ç©ºå­—ç¬¦ä¸²ï¼Œä¹Ÿè§†ä¸ºæ— æ•ˆï¼Œé¿å…èšåˆå‡ºç°ç©ºæè¿°çš„åˆ†ç»„
            if not dev_description:
                return None

            port_status = obj.get("portstatur", "")
            available_count = port_status.count("0")
            used_count = port_status.count("1")
            total_count = len(port_status)

            # è¿”å›ç»“æœå…ƒç»„ (devid, devdescript, ...)
            return (address, dev_description, available_count, used_count, total_count)

        return None

    except requests.exceptions.RequestException:
        return None
    except json.JSONDecodeError:
        return None


# --- ID ç”Ÿæˆå™¨å‡½æ•°ï¼ˆä¸ä¹‹å‰ç›¸åŒï¼‰ ---
def generate_ids_by_pattern() -> Generator[str, None, None]:
    """
    æ ¹æ®ç”¨æˆ·å®šä¹‰çš„æ¨¡å¼ç”Ÿæˆ 8 ä½è®¾å¤‡ ID å­—ç¬¦ä¸²ã€‚
    """
    prefixes = ["40", "50", "60"]
    mid_parts = ["459", "559", "659", "759", "859", "959"]

    for prefix in prefixes:
        for mid in mid_parts:
            full_prefix = prefix + mid
            for suffix_int in range(1000):
                suffix_str = f"{suffix_int:03d}"
                yield full_prefix + suffix_str


# --- æ‰«æä¸»é€»è¾‘ï¼ˆä¸ä¹‹å‰ç›¸åŒï¼Œåªæ˜¯è¿”å›å€¼ç±»å‹ä¸åŒï¼‰ ---
def pattern_scan(
    ids_generator: Generator[str, None, None], max_workers: int = 50
) -> List[Tuple[str, str, int, int, int]]:
    """
    æ¥æ”¶ ID ç”Ÿæˆå™¨ï¼Œå¹¶ä½¿ç”¨å¤šçº¿ç¨‹å’Œ tqdm è¿›è¡Œæ‰«æã€‚
    """
    all_ids = list(ids_generator)
    total_ids = len(all_ids)

    if total_ids == 0:
        print("âŒ æœªç”Ÿæˆä»»ä½•è®¾å¤‡ IDã€‚")
        return []

    print(f"âœ… æ ¹æ®æ¨¡å¼å…±ç”Ÿæˆ {total_ids} ä¸ª IDï¼Œå¼€å§‹å¹¶å‘æ‰«æ...")

    found_results = []

    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        future_to_address = {
            executor.submit(get_device_info, address): address for address in all_ids
        }

        with tqdm(total=total_ids, desc="æ‰«æè¿›åº¦") as pbar:
            for future in as_completed(future_to_address):
                pbar.update(1)

                try:
                    result = future.result()
                    if result:
                        found_results.append(result)
                        pbar.set_postfix_str(f"å‘ç°: {len(found_results)}")
                except Exception:
                    pass

    print("\nâœ… æ‰€æœ‰æ¨¡å¼åŒ¹é… ID æ‰«æå®Œæˆã€‚")
    return found_results


# --- æ ¸å¿ƒèšåˆé€»è¾‘ ---
def aggregate_results(
    results: List[Tuple[str, str, int, int, int]],
) -> List[Dict[str, Any]]:
    """
    æŒ‰è®¾å¤‡æè¿° (devdescript) èšåˆè®¾å¤‡ IDï¼Œå¹¶ä¿ç•™å…¶ä»–ä¿¡æ¯ã€‚

    Args:
        results: åŸå§‹æ‰«æç»“æœåˆ—è¡¨ã€‚

    Returns:
        æŒ‰ devdescript èšåˆåçš„åˆ—è¡¨ã€‚
    """
    aggregated_data = defaultdict(lambda: {"devids": [], "available": 0, "used": 0, "total": 0})

    # ç¬¬ä¸€æ¬¡éå†ï¼šèšåˆ ID å’Œç«¯å£ä¿¡æ¯
    for devid, devdescript, _available, _used, _total in results:
        group = aggregated_data[devdescript]
        group["devids"].append(devid)
        # è¿™é‡Œä»…èšåˆ IDï¼Œç«¯å£ä¿¡æ¯æˆ‘ä»¬ä¸è¿›è¡Œç´¯åŠ ï¼Œä»¥ç¬¬ä¸€æ¬¡å‡ºç°çš„ä¸ºå‡†ï¼Œä½†ä¸ºäº†ç®€åŒ–ï¼Œæˆ‘ä»¬åªè¾“å‡º ID
        # å¦‚æœéœ€è¦ä¿ç•™ç«¯å£ä¿¡æ¯ï¼Œéœ€è¦æ›´å¤æ‚çš„é€»è¾‘æ¥å†³å®šä¿ç•™å“ªä¸ªè®¾å¤‡çš„ç«¯å£æ•°æ®

    # ç¬¬äºŒæ¬¡éå†ï¼šæ ¼å¼åŒ–æœ€ç»ˆè¾“å‡ºåˆ—è¡¨
    final_output = []
    for devdescript, data in aggregated_data.items():
        # å°† ID åˆ—è¡¨è½¬æ¢ä¸ºæ‰€éœ€çš„å­—ç¬¦ä¸²å½¢å¼ "[id1,id2,id3]"
        devids_str = f"[{','.join(data['devids'])}]"

        final_output.append(
            {
                "devdescript": devdescript,
                "device_ids": devids_str,
            }
        )

    return final_output


# --- CSV è¾“å‡ºå‡½æ•°ï¼ˆé’ˆå¯¹èšåˆæ ¼å¼ï¼‰ ---
def write_to_csv(
    aggregated_results: List[Dict[str, Any]],
    output_filename: str = "aggregated_device_results.csv",
):
    """
    å°†èšåˆåçš„ç»“æœå†™å…¥ CSV æ–‡ä»¶ã€‚
    CSV å¤´éƒ¨ä¸º: devdescript, device_ids
    """
    if not aggregated_results:
        print("ğŸš« æ— æœ‰æ•ˆè®¾å¤‡æ•°æ®ï¼Œä¸ç”Ÿæˆ CSV æ–‡ä»¶ã€‚")
        return

    # å®šä¹‰ CSV è¡¨å¤´
    fieldnames = ["devdescript", "device_ids"]

    try:
        with open(output_filename, "w", newline="", encoding="utf-8") as f:
            writer = csv.DictWriter(f, fieldnames=fieldnames)

            writer.writeheader()  # å†™å…¥è¡¨å¤´
            writer.writerows(aggregated_results)  # å†™å…¥æ•°æ®è¡Œ

        print(f"\nğŸ‰ æˆåŠŸå°† {len(aggregated_results)} ç»„è®¾å¤‡ä¿¡æ¯å†™å…¥æ–‡ä»¶: **{output_filename}**")
    except Exception as e:
        print(f"\nâŒ å†™å…¥ CSV æ–‡ä»¶å¤±è´¥: {e}")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="æ ¹æ®ç‰¹å®šæ¨¡å¼æ‰«æè®¾å¤‡ä¿¡æ¯ï¼ŒæŒ‰æè¿°èšåˆ ID å¹¶è¾“å‡º CSVã€‚"
    )
    parser.add_argument("--workers", type=int, default=50, help="å¹¶å‘çº¿ç¨‹æ•° (é»˜è®¤: 50)")
    parser.add_argument(
        "--output",
        type=str,
        default="aggregated_device_results.csv",
        help="CSV è¾“å‡ºæ–‡ä»¶å (é»˜è®¤: aggregated_device_results.csv)",
    )

    args = parser.parse_args()

    # 1. ç”Ÿæˆ ID
    ids_to_scan = generate_ids_by_pattern()

    # 2. æ‰«æ (è·å–æ‰€æœ‰è¯¦ç»†æ•°æ®)
    found_devices_detail = pattern_scan(ids_to_scan, args.workers)

    # 3. èšåˆç»“æœ (æŒ‰ devdescript åˆ†ç»„)
    aggregated_data = aggregate_results(found_devices_detail)

    # 4. å†™å…¥ CSV æ–‡ä»¶
    write_to_csv(aggregated_data, args.output)
